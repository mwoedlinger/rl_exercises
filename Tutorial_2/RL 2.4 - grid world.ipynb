{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7877e00",
   "metadata": {},
   "source": [
    "### Simple 4 × 4 grid world (programming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060424b6",
   "metadata": {},
   "source": [
    "Implement a 4×4 grid world with two terminal states in the upper left\n",
    "corner and lower right corners (resulting in 14 non-terminal states).\n",
    "The four actions 𝒜 = {up, down, left,right} act deterministically, the\n",
    "discount factor is 𝛾 = 1, and the reward is always equal to −1. Ensure\n",
    "that a maximum number of time steps can be specified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d287eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19372e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=0):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cf0f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grid:\n",
    "    \n",
    "    def __init__(self, w, h):\n",
    "        self._w = w\n",
    "        self._h = h\n",
    "        \n",
    "        self.R = -np.ones((w, h))\n",
    "        self.actions = {\n",
    "            \"up\": 0,\n",
    "            \"down\": 1,\n",
    "            \"left\": 2,\n",
    "            \"right\": 3\n",
    "        }\n",
    "        \n",
    "        self.terminal = [(0,0), (w-1, h-1)]\n",
    "                    \n",
    "    def sprime(self, s:np.array, a:int) -> tuple:\n",
    "        # actions: (0,1,2,3) = (up, down, left, right)\n",
    "        actions = {\n",
    "            0: np.array((-1, 0)),\n",
    "            1: np.array((1, 0)),\n",
    "            2: np.array((0, -1)),\n",
    "            3: np.array((0, 1))\n",
    "        }\n",
    "        s_prime = s + actions[a]\n",
    "        s_prime[0] = max(min(s_prime[0], self._w-1), 0)\n",
    "        s_prime[1] = max(min(s_prime[1], self._h-1), 0)\n",
    "        \n",
    "        return tuple(s_prime)\n",
    "\n",
    "    def reward(self, s:np.array, a: int) -> float:\n",
    "        s_prime = self.sprime(s, a)\n",
    "        reward = self.R[s_prime[0], s_prime[1]]\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def cumulative_reward(self, s, π, γ=0.9, max_steps=1):\n",
    "        if s in self.terminal:\n",
    "            return self.R[s]\n",
    "        \n",
    "        reward = 0\n",
    "        \n",
    "        for a in range(π.shape[0]):\n",
    "            sprime = self.sprime(s, a)\n",
    "            \n",
    "            if max_steps > 1:\n",
    "                reward += π[a, s[0], s[1]]*(self.reward(s, a) + γ*self.cumulative_reward(sprime, π, γ, max_steps-1))\n",
    "            else:\n",
    "                reward += π[a, s[0], s[1]]*self.reward(s, a)\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "104b3d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 4, 4\n",
    "\n",
    "g = Grid(w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59dac11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A policy function is a matrix \"policy\" with shape (#actions, grid_w, grid_h) \n",
    "# where policy[a, x, y] is the probability of adction a in state (x, y).\n",
    "# actions: (1,2,3,4) = (up, down, left, right)\n",
    "\n",
    "# π = softmax(np.random.rand(4, w, h)); # random policy\n",
    "π = softmax(np.ones((4, w, h))); # equiprob policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01214ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.734375"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.cumulative_reward((3,2), π, γ=1.0, max_steps=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cf54b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.reward((2,2), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b8fbe0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.sprime((1,2), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62c882e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.sprime((0,2), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3419e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
